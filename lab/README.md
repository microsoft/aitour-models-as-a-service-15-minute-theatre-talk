# Session folder

This folder contains the public facing files for the lab `DIS188`.

## DIS188: Azure AI Foundry Models as a Service 15-minute theatre talk

You'll learn anbout AI Foundry Models as a Service and the Azure AI Model Inference SDKs. The goal is to showcase the variety of models accessible through Azure AI Foundry, emphasize their deployment simplicity, and the developer's flexibility to select different models according to requirements without code changes using the Azure AI Model Inference SDKs.

### 1. Setting up Azure Resources
- **Objective**: Learn how to create Azure AI Foundry hubs and projects.
- **Key Takeaways**:
  - Understand the deployment process for serverless models, which are cost-effective and scalable.
  - Familiarize yourself with the hub and project setup process.

### 2. Deploying Models as a Service
- **Objective**: Learn how to manage hubs, projects, and deployments within Azure AI Foundry.
- **Key Activities**:
  - Work with the Azure AI Foundry interface to manage AI resources.
  - Use the playground feature to interact with deployed models, test prompts, and customize system messages.

### 3. Introduction to the Azure AI Model Inference SDK
- **Objective**: Understand how the Azure AI Model Inference SDK simplifies integrating AI models into applications.
- **Key Takeaways**:
  - Learn how to switch between models (e.g., Mistral and Phi 3) without changing code.
  - Run the demo in GitHub Codespaces or VS Code Dev Containers.
  - Set up environment variables and debug the code to explore model-specific outputs.

### Lab Highlights
- **Flexibility**: Seamlessly switch between models using the Azure AI Model Inference SDK.
- **Simplicity**: Easy deployment and management of AI models via Azure AI Foundry.
- **Cost-Effectiveness**: Utilize serverless models for scalable and budget-friendly AI solutions.
